{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.21.225.129:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>kafka-example</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fc1d0113c10>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "scala_version = '2.12'\n",
    "spark_version = '3.5.0'\n",
    "packages = [\n",
    "    f'org.apache.spark:spark-sql-kafka-0-10_{scala_version}:{spark_version}',\n",
    "    'org.apache.kafka:kafka-clients:3.6.0'\n",
    "]\n",
    "spark = SparkSession.builder.master('local').appName('kafka-example').config('spark.jars.packages', ','.join(packages)).getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'{\"Item_Identifier\":\"NCW18\",\"Item_Weight\":15.1,\"Item_Fat_Content\":\"Low Fat\",\"Item_Visibility\":0.0,\"Item_Type\":\"Household\",\"Item_MRP\":235.5248,\"Outlet_Identifier\":\"OUT045\",\"Outlet_Establishment_Year\":2002,\"Outlet_Size\":null,\"Outlet_Location_Type\":\"Tier 2\",\"Outlet_Type\":\"Supermarket Type1\",\"time_interval\":\"2023-12-29 15:35:43\"}'\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'isNull'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 37\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(message_values)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Replace null values with a default value\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m message_values \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0.0\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39misNull() \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m message_values]\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Chuyển đổi kiểu dữ liệu của cột Item_Weight sang FloatType\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# message_values = message_values.withColumn(\"Item_Weight\", message_values[\"Item_Weight\"].cast(FloatType()))\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Create a Row based on the schema\u001b[39;00m\n\u001b[1;32m     43\u001b[0m row \u001b[38;5;241m=\u001b[39m [message_values[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(schema))]\n",
      "Cell \u001b[0;32mIn[36], line 37\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(message_values)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Replace null values with a default value\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m message_values \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0.0\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misNull\u001b[49m() \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m message_values]\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Chuyển đổi kiểu dữ liệu của cột Item_Weight sang FloatType\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# message_values = message_values.withColumn(\"Item_Weight\", message_values[\"Item_Weight\"].cast(FloatType()))\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Create a Row based on the schema\u001b[39;00m\n\u001b[1;32m     43\u001b[0m row \u001b[38;5;241m=\u001b[39m [message_values[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(schema))]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'isNull'"
     ]
    }
   ],
   "source": [
    "from kafka import KafkaConsumer\n",
    "import time\n",
    "from pyspark.ml.regression import LinearRegressionModel\n",
    "from pyspark.sql.types import * \n",
    "from pyspark.ml.feature import VectorAssembler, StandardScalerModel\n",
    "\n",
    "kafka_topic_name = 'turtorial15'\n",
    "kafka_bootstrap_servers = 'localhost:9092'\n",
    "\n",
    "consumer = KafkaConsumer(kafka_topic_name, bootstrap_servers=kafka_bootstrap_servers)\n",
    "\n",
    "model_path = \"./linear_regression_model\"\n",
    "linearModel = LinearRegressionModel.load(model_path)\n",
    "\n",
    "# Define the schema\n",
    "schema = StructType([\n",
    "               StructField('Item_Identifier', StringType(), True),\n",
    "               StructField('Item_Weight', FloatType(), True),\n",
    "               StructField('Item_Fat_Content', StringType(), True),\n",
    "               StructField('Item_Visibility', FloatType(), True),\n",
    "               StructField('Item_Type', StringType(), True),\n",
    "               StructField('Item_MRP', FloatType(), True),\n",
    "               StructField('Outlet_Identifier', StringType(), True),\n",
    "               StructField('Outlet_Establishment_Year', IntegerType(), True),\n",
    "               StructField('Outlet_Size', StringType(), True),\n",
    "               StructField('Outlet_Location_Type', StringType(), True),\n",
    "               StructField('Outlet_Type', StringType(), True),\n",
    "               StructField('Time_Interval', TimestampType(), True),\n",
    "              ])\n",
    "\n",
    "for message in consumer:\n",
    "    # Extract the message from the ConsumerRecord object\n",
    "    message_values = message.value\n",
    "    print(message_values)\n",
    "\n",
    "    # Replace null values with a default value\n",
    "    message_values = ['0.0' if x.isNull() else x for x in message_values]\n",
    "    \n",
    "    # Create a Row based on the schema\n",
    "    row = [message_values[i] for i in range(len(schema))]\n",
    "    \n",
    "    # Create a DataFrame from the Row\n",
    "    row = Row(*message_values)\n",
    "    df = spark.createDataFrame([row], schema=schema)\n",
    "\n",
    "    df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
